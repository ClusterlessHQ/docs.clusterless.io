= How Clusterless Can Help
:keywords:
:navtitle: How Clusterless Can Help

Clusterless was designed to aid Data Engineers, Data Scientists, and Data/ML Ops personnel create data oriented
applications that require minimal attention after deployment. And to allow teams to collaborate without strict coupling
of their data processes.

Regardless of the role, Clusterless can help by allowing developers to focus on the code first, data pipelines second,
and the infrastructure last.

== Infrastructure Last

Clusterless is not a server or an application that runs on a remote host. There is nothing to reboot, monitor, or pay
for when idle.

It is a command line tool for deploying data oriented stacks on a cloud provider using native primitives provided by the
given cloud.

Clusterless relies on a JSON based declarative language to describe what to deploy, and where to deploy it.

Because it's declarative, what infrastructure is used at configuration is a function of the cloud provider and the
capabilities required. Sometimes choices are offered or required based on expected load or similar concerns.

This JSON declaration is typically part of the application code that Clusterless would deploy. And, in turn, deployments
can be run through standard CI/CD pipelines.

== Pipelines Second

A pipeline is a DAG (directed acyclic graph) of nodes and arcs (edges). It may start with one node (a dataset) and
branch through arcs into new nodes (new datasets). These new nodes in turn may have dependent arcs.

Nodes, or datasets, are typically continuously changing in size and periodically changing in schema or format.

Arcs, or data processing applications, are continuously processing data as it arrives, periodically evolve as
upstream data or requirement change, and may be provided services (e.g. AWS Glue and AWS Athena).

Nodes and arcs often have different owners and stakeholders.

Subsequently, the overall pipeline is not static, but dynamic. New arcs and nodes are added and/or removed
frequently.

For developers, stakeholders, and teams to be successful in their roles, they cannot be required coordinate with each
other for every change.

Clusterless allows developers and teams to work as independently as possible. If a new arc needs to be deployed into the
pipeline DAG, it only needs to subscribe to the events emitted by the nodes (datasets) that it is dependent on.
Clusterless handles all event publishing and subscriptions.

If an upstream dataset provider needs to make incompatible changes, the data processing arc can be deployed so that it
emits a new dataset under a new version. If needed, the new arc can be back-filled, so that the new dataset has
sufficient historical data. If a minor bug (empty string instead of null field values) is found in the data, it can be
replayed in place.

Clusterless maintains multiple types of metadata that enable capabilities like back-filling, replaying, and gap
reporting.

Data pipelines are heterogeneous. When done right, they consist of mostly reusable components. And some bespoke
components provided by custom code.

== Code First

Data oriented code used for data management, feature engineering, or machine learning, may do different things with data
but all of these workloads read data and write data.

Clusterless standardizes the contract these workloads code against.

That is, where to read data from and where to write it to is managed outside the workload, passed to the workload as
parameters at runtime. The only thing a workload has to return to the Clusterless framework is an accounting of what
data it wrote.

This code can be anything a Docker container can run, or can be coupled to capabilities a given cloud provider might offer
(e.g. AWS Lambda).

